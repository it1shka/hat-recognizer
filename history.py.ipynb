{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First variant of CNN\n",
    "1. Accepts 3 RGB channels (later I decided that grayscaling is the way)\n",
    "2. I think it is inefficient because it takes color in consideration, but \n",
    "  type of hat depends only on shape\n",
    "3. Once I trained it to 60% accuracy, but it seems it was just an accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class HeadgearRecognizer1(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.extractor = nn.Sequential(\n",
    "      nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "      nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    )\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Linear(32 * 56 * 56, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(0.15),\n",
    "\n",
    "      nn.Linear(128, 64),\n",
    "      nn.ReLU(),\n",
    "\n",
    "      nn.Linear(64, 20),\n",
    "    )\n",
    "    self.softmax = nn.LogSoftmax(dim=1)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.extractor(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.classifier(x)\n",
    "    return self.softmax(x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second variant of CNN\n",
    "1. Can be trained up to <60%\n",
    "2. I understood that u can actually use ConvUnit(x, x) -- same amount of in_channels / out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ConvUnit(nn.Module):\n",
    "  def __init__(self, in_channels: int, out_channels: int, conv_kernel: int = 3, pool_kernel: int = 2) -> None:\n",
    "    super().__init__()\n",
    "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=conv_kernel, stride=1, padding=1)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.pool = nn.MaxPool2d(kernel_size=pool_kernel, stride=pool_kernel)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.conv(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "    return x\n",
    "\n",
    "class DenseUnit(nn.Module):\n",
    "  def __init__(self, in_features: int, out_features: int, dropout: int = 0) -> None:\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(in_features, out_features)\n",
    "    self.relu = nn.ReLU()\n",
    "    if dropout > 0:\n",
    "      self.dropout = nn.Dropout(dropout)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.linear(x)\n",
    "    x = self.relu(x)\n",
    "    if hasattr(self, 'dropout'):\n",
    "      x = self.dropout(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class HeadgearRecognizer2(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.extractor = nn.Sequential(\n",
    "      ConvUnit(1, 32),\n",
    "      ConvUnit(32, 64),\n",
    "      ConvUnit(64, 64),\n",
    "      ConvUnit(64, 128),\n",
    "    )\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.classifier = nn.Sequential(\n",
    "      DenseUnit(25088, 1024),\n",
    "      DenseUnit(1024, 512, dropout=0.1),\n",
    "      DenseUnit(512, 256),\n",
    "      DenseUnit(256, 128, dropout=0.1),\n",
    "      DenseUnit(128, 20),\n",
    "    )\n",
    "    self.softmax = nn.LogSoftmax(dim=1)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.extractor(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.classifier(x)\n",
    "    return self.softmax(x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important remark\n",
    "Once I started using learning_rate = 0.001 and batch_size = 64, my neural networks started educating.\n",
    "Before I had a problem that the progress of loss function was stopping on some particular value like 0.0939, and the accuracy was \n",
    "~= 7%\n",
    "\n",
    "But yeah, the moment I used learning_rate=0.001 and batch_size = 64 everything seems to be working now"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third variant of CNN\n",
    "1. Can be trained up to 70%\n",
    "2. Has increased kernel size in the first ConvUnit (which is probably important!)\n",
    "3. In the subsequent networks I will try to increase this number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class HeadgearRecognizer3(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.extractor = nn.Sequential(\n",
    "      ConvUnit(1, 32, conv_kernel=7, pool_kernel=4),\n",
    "      ConvUnit(32, 64),\n",
    "      ConvUnit(64, 128),\n",
    "      ConvUnit(128, 128),\n",
    "    )\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.classifier = nn.Sequential(\n",
    "      DenseUnit(4608, 512),\n",
    "      DenseUnit(512, 128, dropout=0.1),\n",
    "      DenseUnit(128, 20),\n",
    "    )\n",
    "    self.softmax = nn.LogSoftmax(dim=1)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.extractor(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.classifier(x)\n",
    "    return self.softmax(x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth variant of CNN\n",
    "1. Can be trained up to 75%\n",
    "2. Increased kernel sizes in the first two ConvUnits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class HeadgearRecognizer4(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.extractor = nn.Sequential(\n",
    "      ConvUnit(1, 32, conv_kernel=7, pool_kernel=5),\n",
    "      ConvUnit(32, 64, conv_kernel=5, pool_kernel=3),\n",
    "      ConvUnit(64, 128),\n",
    "    )\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.classifier = nn.Sequential(\n",
    "      DenseUnit(6272, 512),\n",
    "      DenseUnit(512, 128, dropout=0.25),\n",
    "      DenseUnit(128, 20),\n",
    "    )\n",
    "    self.softmax = nn.LogSoftmax(dim=1)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.extractor(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.classifier(x)\n",
    "    return self.softmax(x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth variant of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class HeadgearRecognizer5(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.extractor = nn.Sequential(\n",
    "      ConvUnit(1, 16, conv_kernel=7, pool_kernel=3),\n",
    "      ConvUnit(16, 32, conv_kernel=7, pool_kernel=3),\n",
    "      ConvUnit(32, 64),\n",
    "      ConvUnit(64, 128),\n",
    "    )\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.classifier = nn.Sequential(\n",
    "      DenseUnit(3200, 512),\n",
    "      DenseUnit(512, 256, dropout=0.25),\n",
    "      DenseUnit(256, 128, dropout=0.25),\n",
    "      DenseUnit(128, 20),\n",
    "    )\n",
    "    self.softmax = nn.LogSoftmax(dim=1)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.extractor(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.classifier(x)\n",
    "    return self.softmax(x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6th variant of CNN\n",
    "1. I started adding some batch normalization and I think it worked out\n",
    "2. I am using 3 channels for RGB colors, while in previous iterations I was using only one channel for grayscaled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ConvUnit(nn.Module):\n",
    "  def __init__(self, in_channels: int, out_channels: int, conv_kernel: int = 3, pool_kernel: int = 2, normalization: bool = True) -> None:\n",
    "    super().__init__()\n",
    "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=conv_kernel, stride=1, padding=1)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.normalize = normalization\n",
    "    if normalization:\n",
    "      self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "    self.pool = nn.MaxPool2d(kernel_size=pool_kernel, stride=pool_kernel)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.conv(x)\n",
    "    x = self.relu(x)\n",
    "    if self.normalize:\n",
    "      x = self.batch_norm(x)\n",
    "    x = self.pool(x)\n",
    "    return x\n",
    "\n",
    "class DenseUnit(nn.Module):\n",
    "  def __init__(self, in_features: int, out_features: int, dropout: int = 0, normalization: bool = True) -> None:\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(in_features, out_features)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.normalize = normalization\n",
    "    if normalization:\n",
    "      self.batch_norm = nn.BatchNorm1d(out_features)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.linear(x)\n",
    "    x = self.relu(x)\n",
    "    if self.normalize:\n",
    "      x = self.batch_norm(x)\n",
    "    x = self.dropout(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class HeadgearRecognizer6(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.extractor = nn.Sequential(\n",
    "      ConvUnit(3, 32, conv_kernel=5, pool_kernel=3),\n",
    "      ConvUnit(32, 64),\n",
    "      ConvUnit(64, 128),\n",
    "    )\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.classifier = nn.Sequential(\n",
    "      DenseUnit(41472 , 1024),\n",
    "      DenseUnit(1024, 512, dropout=0.10),\n",
    "      DenseUnit(512, 256, dropout=0.25),\n",
    "      DenseUnit(256, 20, normalization=False),\n",
    "    )\n",
    "    self.softmax = nn.LogSoftmax(dim=1)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.extractor(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.classifier(x)\n",
    "    return self.softmax(x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7th attempt to build a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class HeadgearRecognizer7(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.extractor = nn.Sequential(\n",
    "      ConvUnit(3, 32, conv_kernel=5, pool_kernel=3),\n",
    "      ConvUnit(32, 64),\n",
    "      ConvUnit(64, 128),\n",
    "      ConvUnit(128, 256),\n",
    "    )\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.classifier = nn.Sequential(\n",
    "      DenseUnit(20736, 1024),\n",
    "      DenseUnit(1024, 512, dropout=0.25),\n",
    "      DenseUnit(512, 256, dropout=0.25),\n",
    "      DenseUnit(256, 20, normalization=False),\n",
    "    )\n",
    "    self.softmax = nn.LogSoftmax(dim=1)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.extractor(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.classifier(x)\n",
    "    return self.softmax(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
